{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "## Setting up\n",
    "### set module paths and data path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "minian_path = \".\"\n",
    "dpath = \"./demo_movies/\"\n",
    "meta_dict={'session_id': -1, 'session': -2, 'animal': -3}\n",
    "chunks = {'frame': 1000, 'height': 200, 'width': 200, 'unit_id':20}\n",
    "in_memory = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(minian_path)\n",
    "import gc\n",
    "import psutil\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import holoviews as hv\n",
    "import paramnb\n",
    "import matplotlib.pyplot as plt\n",
    "import bokeh.plotting as bpl\n",
    "import dask.array as da\n",
    "import pandas as pd\n",
    "import dask\n",
    "import datashader as ds\n",
    "from holoviews.operation.datashader import datashade, regrid, dynspread\n",
    "from datashader.colors import Sets1to3\n",
    "from dask.diagnostics import ProgressBar\n",
    "from IPython.core.display import display, HTML\n",
    "from dask.distributed import Client, progress\n",
    "from minian.utilities import load_videos, varray_to_tif, save_cnmf, save_movies, scale_varr, save_variable\n",
    "from minian.preprocessing import remove_brightspot, gradient_norm, denoise, remove_background\n",
    "from minian.motion_correction import estimate_shift_fft, apply_shifts, interpolate_frame, mask_shifts\n",
    "from minian.initialization import seeds_init, gmm_refine, pnr_refine, intensity_refine, ks_refine, seeds_merge, initialize\n",
    "from minian.cnmf import get_noise_fft, get_noise_welch, update_spatial, update_temporal, unit_merge\n",
    "from minian.visualization import VArrayViewer, MCViewer, CNMFViewer, generate_videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### module initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "dpath = os.path.abspath(dpath)\n",
    "hv.notebook_extension('bokeh', width=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing\n",
    "### loading videos and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "varr = load_videos(dpath, in_memory=in_memory, dtype=np.float32, resample=dict(frame=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "varr_ref = scale_varr(varr.chunk(dict(height='auto', width='auto', frame=200)))\n",
    "if in_memory:\n",
    "    with ProgressBar():\n",
    "        varr_ref = varr_ref.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%output size=100\n",
    "vaviewer = VArrayViewer([varr_ref], framerate=5)\n",
    "display(vaviewer.widgets)\n",
    "vaviewer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varr_ref = varr_ref.isel(height=slice(None, -2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "save_variable(varr_ref.rename(\"org\"), dpath, 'minian', meta_dict=meta_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bright spots removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "varr_ref = remove_brightspot(varr_ref.chunk(dict(height=-1, width=-1, frame='auto')), thres=2)\n",
    "if in_memory:\n",
    "    with ProgressBar():\n",
    "        varr_ref = varr_ref.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### estimate gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with ProgressBar():\n",
    "    varr_gradient = gradient_norm(varr_ref.isel(frame=0)).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kappa = varr_gradient.quantile(0.9).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### anisotropic diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "varr_ref = denoise(varr_ref, 'anisotropic', niter=10, kappa=kappa, gamma=0.25, option=2)\n",
    "if in_memory:\n",
    "    with ProgressBar(), dask.config.set(scheduler='processes'):\n",
    "        varr_ref = varr_ref.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### background removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "varr_ref = remove_background(varr_ref, method='tophat', wnd=10)\n",
    "if in_memory:\n",
    "    with ProgressBar(), dask.config.set(scheduler='processes'):\n",
    "        varr_ref = varr_ref.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "varr_ref = scale_varr(varr_ref.chunk(dict(height='auto', width='auto', frame=200)))\n",
    "if in_memory:\n",
    "    with ProgressBar():\n",
    "        varr_ref = varr_ref.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualization of pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%output size=70\n",
    "vaviewer = VArrayViewer([varr, varr_ref.rename('varr_ref')], framerate=5, ds_rate=2)\n",
    "display(vaviewer.widgets)\n",
    "vaviewer.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## motion correction\n",
    "### estimate shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "varr_fft, res = estimate_shift_fft(varr_ref, on='perframe')\n",
    "if in_memory:\n",
    "    with ProgressBar():\n",
    "        res = res.compute()\n",
    "shifts = res.sel(variable = ['height', 'width'])\n",
    "corr = res.sel(variable='corr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### masking and interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "shifts_ma, mask = mask_shifts(varr_fft, corr, shifts, z_thres=-1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "varr_mc = interpolate_frame(varr_mc.compute().rename('varr_mc'), mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### apply shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "shifts_cum = shifts.cumsum('frame')\n",
    "shifts_cum = np.around(shifts_cum.fillna(0)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "varr_ref = varr_ref.chunk(dict(height=-1, width=-1, frame='auto'))\n",
    "varr_mc = apply_shifts(varr_ref, shifts_cum)\n",
    "if in_memory:\n",
    "    with ProgressBar():\n",
    "        varr_mc = varr_mc.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualization of motion-correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%output size=100 fps=5\n",
    "vaviewer = VArrayViewer([varr_ref.rename('varr_ref'), varr_mc.rename('mc')], framerate=5)\n",
    "display(vaviewer.widgets)\n",
    "vaviewer.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualization of shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%output size=100\n",
    "%%opts Curve [width=500, tools=['hover']]\n",
    "hv.NdOverlay(dict(width=hv.Curve(shifts.sel(variable='width')), height=hv.Curve(shifts.sel(variable='height'))))\\\n",
    "+ hv.NdOverlay(dict(width=hv.Curve(shifts_cum.sel(variable='width')), height=hv.Curve(shifts_cum.sel(variable='height'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save result as DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "save_variable(varr_mc.rename('Y'), dpath, 'minian', meta_dict=meta_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "minian = xr.open_dataset(os.path.join(dpath, 'minian.nc'), autoclose=True)\n",
    "Y = minian['Y'].load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "seeds = seeds_init(Y, method='rolling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "seeds_gmm = gmm_refine(Y, seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "seeds_pnr = pnr_refine(Y, seeds_gmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "seeds_int = intensity_refine(Y, seeds_pnr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "seeds_ks = ks_refine(Y, seeds_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "seeds_mrg = seeds_merge(Y, seeds_ks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "A, C, b, f = initialize(Y, seeds_mrg, chk=dict(height=200, width=200, frame=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = dict(plot=dict(height=300, width=300))\n",
    "regrid(hv.Image(A.sum('unit_id'), kdims=['width', 'height'])).opts(**opts) + regrid(hv.Image(C, kdims=['frame', 'unit_id'])).opts(**opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "save_variable(A.rename('A_init').rename(unit_id='unit_id_init'), dpath, 'minian', meta_dict=meta_dict)\n",
    "save_variable(C.rename('C_init').rename(unit_id='unit_id_init'), dpath, 'minian', meta_dict=meta_dict)\n",
    "save_variable(b.rename('b_init'), dpath, 'minian', meta_dict=meta_dict)\n",
    "save_variable(f.rename('f_init'), dpath, 'minian', meta_dict=meta_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNMF\n",
    "### loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "chk = chunks.copy()\n",
    "chk['unit_id_init'] = chk.pop('unit_id')\n",
    "minian = xr.open_dataset(os.path.join(dpath, 'minian.nc'), chunks=chk)\n",
    "Y = minian['Y']\n",
    "A_init = minian['A_init'].rename(unit_id_init='unit_id')\n",
    "C_init = minian['C_init'].rename(unit_id_init='unit_id')\n",
    "b_init = minian['b_init']\n",
    "f_init = minian['f_init']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### estimate spatial noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "sn_spatial, psd = get_noise_fft(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Image [height=300, width=800] (cmap='Viridis')\n",
    "psd_flt = psd.stack(spatial=['height', 'width'])\n",
    "hv_psd = hv.Image(psd_flt.assign_coords(spatial=range(psd_flt.sizes['spatial'])), kdims=['spatial', 'freq'])\n",
    "regrid(hv_psd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test parameters for spatial update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opts_A = dict(plot=dict(height=480, width=752), style=dict(cmap='Viridis'))\n",
    "opts_C = dict(plot=dict(height=480, width=1000), style=dict(cmap='Viridis'))\n",
    "sprs_ls = [5e-6, 5e-3, 0.5, 5]\n",
    "units = np.random.choice(A_init.coords['unit_id'], 20)\n",
    "A_dict = dict()\n",
    "for cur_sprs in sprs_ls:\n",
    "    cur_A, cur_b, cur_C, cur_f = update_spatial(\n",
    "        Y, A_init.sel(unit_id=units),\n",
    "        b_init, C_init.sel(unit_id=units), f_init, sn_spatial, sparse_penal=cur_sprs)\n",
    "    hv_cur_A = hv.Image(cur_A.sum('unit_id'), kdims=['width', 'height']).opts(**opts_A)\n",
    "    hv_cur_C = hv.Image(cur_C, kdims=['frame', 'unit_id']).opts(**opts_C)\n",
    "    A_dict[cur_sprs] = (hv_cur_A + hv_cur_C).cols(1)\n",
    "hv_res = hv.HoloMap(A_dict, kdims=['sparse_penalty'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Image [colorbar=True] {+axiswise}\n",
    "hv_res.collate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### first spatial update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "A_spatial, b_spatial, C_spatial, f_spatial = update_spatial(\n",
    "    Y, A_init, b_init, C_init, f_init, sn_spatial, sparse_penal=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%opts Image [colorbar=True] (cmap='Viridis')\n",
    "regrid(hv.Image(A_init.sum('unit_id'), kdims=['width', 'height'])).opts(plot=dict(height=480, width=752))\\\n",
    "+ regrid(hv.Image(A_spatial.sum('unit_id').rename('A_spatial'), kdims=['width', 'height'])).opts(plot=dict(height=480, width=752)).redim.range(A_spatial=(0, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test parameters for temporal update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import linalg\n",
    "def construct_G(g, T):\n",
    "    cur_c, cur_r = np.zeros(T), np.zeros(T)\n",
    "    cur_c[0] = 1\n",
    "    cur_r[0] = 1\n",
    "    cur_c[1:len(g) + 1] = -g\n",
    "    return linalg.toeplitz(cur_c, cur_r)\n",
    "\n",
    "def normalize(a): return np.interp(a, (a.min(), a.max()), (0, +1))\n",
    "\n",
    "def convolve_G(s, g):\n",
    "    G = construct_G(g, len(s))\n",
    "    try:\n",
    "        c = linalg.inv(G).dot(s)\n",
    "    except LinAlgError:\n",
    "        c = s.copy()\n",
    "    return c\n",
    "\n",
    "def construct_pulse_response(g):\n",
    "    s = np.zeros(500)\n",
    "    s[10] = 1\n",
    "    c = convolve_G(s, g)\n",
    "    return s, c\n",
    "\n",
    "def visualize_temporal_update(YA, C, S, g, sig, norm=True):\n",
    "    if norm:\n",
    "        C_norm = xr.apply_ufunc(normalize, C, input_core_dims=[['frame']], output_core_dims=[['frame']], vectorize=True, dask='parallelized', output_dtypes=[C.dtype])\n",
    "        S_norm = xr.apply_ufunc(normalize, S, input_core_dims=[['frame']], output_core_dims=[['frame']], vectorize=True, dask='parallelized', output_dtypes=[S.dtype])\n",
    "        YA_norm = xr.apply_ufunc(normalize, YA.compute(), input_core_dims=[['frame']], output_core_dims=[['frame']], vectorize=True, dask='parallelized', output_dtypes=[YA.dtype])\n",
    "        sig_norm = xr.apply_ufunc(normalize, sig, input_core_dims=[['frame']], output_core_dims=[['frame']], vectorize=True, dask='parallelized', output_dtypes=[sig.dtype])\n",
    "    else:\n",
    "        C_norm = C\n",
    "        S_norm = S\n",
    "        YA_norm = YA\n",
    "        sig_norm = sig\n",
    "    s_pul, c_pul = xr.apply_ufunc(construct_pulse_response, g.compute(), input_core_dims=[['lag']], output_core_dims=[['frame'], ['frame']], vectorize=True, output_sizes=dict(t=500))\n",
    "    s_pul = s_pul.assign_coords(frame=np.arange(500))\n",
    "    c_pul = c_pul.assign_coords(frame=np.arange(500))\n",
    "    hv_s_pul = hv.Dataset(s_pul.rename('s_pul'), kdims=['unit_id', 'frame'])\n",
    "    hv_c_pul = hv.Dataset(c_pul.rename('c_pul'), kdims=['unit_id', 'frame'])\n",
    "    with ProgressBar():\n",
    "        hv_C = hv.Dataset(C_norm.compute().rename('Calcium trace'), kdims=['unit_id', 'frame'])\n",
    "        hv_S = hv.Dataset(S_norm.compute().rename('Spike'), kdims=['unit_id', 'frame'])\n",
    "        hv_YA = hv.Dataset(YA_norm.compute().rename('Raw'), kdims=['unit_id', 'frame'])\n",
    "        hv_sig = hv.Dataset(sig_norm.compute().rename('Fitted'), kdims=['unit_id', 'frame'])\n",
    "    hv_obj = hv_YA.to(hv.Curve, kdims=['frame'], label='Raw Signal').opts(style=dict(alpha=0.7))\\\n",
    "    * hv_C.to(hv.Curve, kdims=['frame'], label='Fitted Calcium Trace')\\\n",
    "    * hv_S.to(hv.Curve, kdims=['frame'], label='Fitted Spikes')\\\n",
    "    * hv_sig.to(hv.Curve, kdims=['frame'], label='Fitted Signal')\\\n",
    "    + hv_c_pul.to(hv.Curve, kdims=['frame'], label='Simulated Calcium')\\\n",
    "    * hv_s_pul.to(hv.Curve, kdims=['frame'], label='Simultaed Spike')\n",
    "    return hv_obj.cols(1)\n",
    "    return hv_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import itertools as itt\n",
    "p_ls = [1]\n",
    "sprs_ls = [0.5, 5]\n",
    "add_ls = [0, 3, 5]\n",
    "noise_ls = [0.45, 0.48, 0.499]\n",
    "C_dict = dict()\n",
    "S_dict = dict()\n",
    "g_dict = dict()\n",
    "vis_dict = dict()\n",
    "for cur_sprs, cur_p, cur_add, cur_noise in itt.product(sprs_ls, p_ls, add_ls, noise_ls):\n",
    "    print(\"processing {}\".format((cur_p, cur_sprs, cur_add, cur_noise)))\n",
    "    YrA, cur_C, cur_S, cur_B, cur_C0, cur_sig, cur_g, = update_temporal(\n",
    "        Y, A_spatial.isel(unit_id=slice(0, 10)), b_spatial, C_spatial.isel(unit_id=slice(0, 10)),\n",
    "        f_spatial, sn_spatial, sparse_penal=cur_sprs, p=cur_p, use_spatial=False, use_smooth=True,\n",
    "        add_lag = cur_add, noise_freq=cur_noise, chk=dict(frame=200, unit_id=20),\n",
    "        cvx_sched=\"processes\")\n",
    "    C_dict[(cur_p, cur_sprs, cur_add, cur_noise)] = cur_C\n",
    "    S_dict[(cur_p, cur_sprs, cur_add, cur_noise)] = cur_S\n",
    "    g_dict[(cur_p, cur_sprs, cur_add, cur_noise)] = cur_g\n",
    "    vis_dict[(cur_p, cur_sprs, cur_add, cur_noise)] = visualize_temporal_update(\n",
    "        YrA, cur_C, cur_S, cur_g, cur_sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Curve [width=1200] {+framewise}\n",
    "hv_res = hv.HoloMap(vis_dict, kdims=['p', 'sparse_penalty', 'add_lag', 'noise_freq']).collate()\n",
    "hv_res.select(unit_id=slice(5, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### first temporal update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "YrA, C_temporal, S_temporal, B_temporal, C0_temporal, sig_temporal, g_temporal = update_temporal(\n",
    "        Y, A_spatial,\n",
    "        b_spatial, C_spatial, f_spatial, sn_spatial, jac_thres=0.2,\n",
    "        noise_freq=0.45, sparse_penal=0.5, p=1, add_lag = 0, use_spatial=False, chk=dict(frame=2000, unit_id=200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%opts Curve [width=1200] {+framewise}\n",
    "visualize_temporal_update(YrA, C_temporal, S_temporal, g_temporal, sig_temporal, normalize=False).select(unit_id = slice(0, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Image [colorbar=True] (cmap='Viridis')\n",
    "hv_c = regrid(hv.Image(C_temporal.rename('c'), kdims=['frame', 'unit_id'])).opts(plot=dict(height=500, width=1000)).redim.range(c=(0, 1))\n",
    "hv_s = regrid(hv.Image(S_temporal.rename('s'), kdims=['frame', 'unit_id'])).opts(plot=dict(height=500, width=1000)).redim.range(s=(0, 0.006))\n",
    "(hv_c + hv_s).cols(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh import models\n",
    "from bokeh.io import export_svgs\n",
    "\n",
    "def flatten(l):\n",
    "    for el in l:\n",
    "        if isinstance(el, collections.Iterable) and not isinstance(el, basestring):\n",
    "            for sub in flatten(el):\n",
    "                yield sub\n",
    "        else:\n",
    "            yield el\n",
    "\n",
    "def _get_figures_core(objs):\n",
    "    if isinstance(objs, list):\n",
    "        objs = [_get_figures_core(plot) for plot in objs]\n",
    "    elif isinstance(objs, (models.Column, models.Row)):\n",
    "        objs = [_get_figures_core(child) for child in objs.children\n",
    "                if not isinstance(child, (models.ToolbarBox,\n",
    "                                          models.WidgetBox))]\n",
    "    return objs\n",
    "\n",
    "def _get_figures(objs):\n",
    "    try:\n",
    "        return list(flatten(_get_figures_core(objs)))\n",
    "    except TypeError:\n",
    "        return [_get_figures_core(objs)]\n",
    "\n",
    "def _save_to_svg(hv_obj, save):\n",
    "    bokeh_obj = hv.renderer('bokeh').get_plot(hv_obj).state\n",
    "    figures = _get_figures(bokeh_obj)\n",
    "    for i, figure in enumerate(figures):\n",
    "        figure.output_backend = 'svg'\n",
    "\n",
    "        if len(figures) != 1:\n",
    "            if not os.path.exists(save):\n",
    "                os.makedirs(save)\n",
    "            tidied_title = figure.title.text\n",
    "            save_fp = os.path.join(\n",
    "                save, '{0}_{1}'.format(tidied_title, i))\n",
    "        else:\n",
    "            save_fp = save\n",
    "\n",
    "        if not save_fp.endswith('svg'):\n",
    "            save_fp = '{0}.{1}'.format(save_fp, 'svg')\n",
    "\n",
    "        export_svgs(figure, save_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv_c = (hv.Image(C_temporal.rename('c'), kdims=['frame', 'unit_id'])\n",
    "        .opts(plot=dict(height=500, width=1000), style=dict(cmap='Viridis'))\n",
    "        .redim.range(c=(0, 1)))\n",
    "_save_to_svg(hv_c, \"/home/phild/hv_c.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merge units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "A_mrg, sig_mrg = unit_merge(A_spatial, sig_temporal, thres_corr=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### second spatial update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "A_spatial_it2, b_spatial_it2, C_spatial_it2, f_spatial_it2 = update_spatial(\n",
    "    Y, A_mrg, b_spatial, sig_mrg, f_spatial, sn_spatial, sparse_penal=0.1, dl_wnd=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_spatial_it2_norm = xr.apply_ufunc(normalize, A_spatial_it2, input_core_dims=[['height', 'width']], output_core_dims=[['height', 'width']], vectorize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regrid(hv.Image(A_spatial.sum('unit_id'), kdims=['width', 'height'])).opts(plot=dict(height=480, width=752))\\\n",
    "+ regrid(hv.Image(A_spatial_it2_norm.sum('unit_id'), kdims=['width', 'height'])).opts(plot=dict(height=480, width=752))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### second temporal update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "YrA, C_temporal_it2, S_temporal_it2, B_temporal_it2, C0_temporal_it2, sig_temporal_it2, g_temporal_it2 = update_temporal(\n",
    "    Y, A_spatial_it2, b_spatial_it2, C_spatial_it2, f_spatial_it2, sn_spatial, jac_thres=0.2,\n",
    "    noise_freq=0.45, sparse_penal=0.5, p=1, add_lag=0, chk=dict(frame=2000, unit_id=200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%opts Curve [width=1200] {+framewise}\n",
    "visualize_temporal_update(\n",
    "    YrA, C_temporal_it2, S_temporal_it2, g_temporal_it2, sig_temporal_it2).select(unit_id=slice(0, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Image [colorbar=True, tools=['hover']] (cmap='Viridis')\n",
    "hv_c = regrid(hv.Image(C_temporal_it2.rename('c'), kdims=['frame', 'unit_id'])).opts(plot=dict(height=500, width=1000)).redim.range(c=(0, 1))\n",
    "hv_s = regrid(hv.Image(S_temporal_it2.rename('s'), kdims=['frame', 'unit_id'])).opts(plot=dict(height=500, width=1000)).redim.range(s=(0, 0.006))\n",
    "(hv_c + hv_s).cols(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "minian.close()\n",
    "save_variable(A_spatial_it2.rename('A'), dpath, 'minian', meta_dict=meta_dict)\n",
    "save_variable(C_temporal_it2.rename('C'), dpath, 'minian', meta_dict=meta_dict)\n",
    "save_variable(S_temporal_it2.rename('S'), dpath, 'minian', meta_dict=meta_dict)\n",
    "save_variable(g_temporal_it2.rename('g'), dpath, 'minian', meta_dict=meta_dict)\n",
    "save_variable(b_spatial_it2.rename('b'), dpath, 'minian', meta_dict=meta_dict)\n",
    "save_variable(f_spatial_it2.rename('f'), dpath, 'minian', meta_dict=meta_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minian = xr.open_dataset(os.path.join(dpath, 'minian.nc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "generate_videos(minian, os.path.join(dpath, \"minian.mp4\"), chk=dict(height=100, width=100, frame=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cnmfviewer = CNMFViewer(minian, minian['Y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cnmfviewer.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "caiman",
   "language": "python",
   "name": "caiman"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "name": "pipeline.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
