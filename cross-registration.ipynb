{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minian_path = \"/home/phild/Documents/sync/project/miniscope/MiniAn/\"\n",
    "caiman_path = \"/home/phild/Documents/sync/project/miniscope/CaImAn/\"\n",
    "dpath = \"/media/share/hdda/Denise/Wired_Valence/Wired_Valence_Organized_Data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "sys.path.append(minian_path)\n",
    "sys.path.append(caiman_path)\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import holoviews as hv\n",
    "import pandas as pd\n",
    "from minian.cross_registration import load_cnm_dataset, get_cnm_list, estimate_shifts, apply_shifts, calculate_centroids, calculate_centroid_distance, calculate_mapping, group_by_session\n",
    "from minian.utilities import resave_varr, update_meta\n",
    "from IPython.core.debugger import set_trace\n",
    "hv.notebook_extension('bokeh', width=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "def subsetting_unit(ds):\n",
    "    ds = ds.sel(unit_id=ds.attrs['unit_mask'])\n",
    "    return ds\n",
    "\n",
    "for anm_path in next(os.walk(dpath))[1]:\n",
    "    print(\"processing: {}\".format(anm_path))\n",
    "    anm_path = os.path.join(dpath, anm_path)\n",
    "    flist = get_cnm_list(anm_path)\n",
    "    if not flist:\n",
    "        continue\n",
    "    shifts, corrs, temps = estimate_shifts(flist, ['mean']*len(flist))\n",
    "    temps_sh = apply_shifts(temps, shifts)\n",
    "    temps = temps.astype(float)\n",
    "    temps_sh = temps_sh.astype(float)\n",
    "    cross_regi = xr.merge([shifts, corrs, temps, temps_sh])\n",
    "    cross_regi.to_netcdf(anm_path + os.sep + \"cross_regi.nc\")\n",
    "    with xr.open_mfdataset(flist, concat_dim='session', preprocess=subsetting_unit) as cnmds:\n",
    "        print(\"\\nloading spatial matrix\")\n",
    "        cnmds['A'].load()\n",
    "        cnmds['b'].load()\n",
    "        print(\"applying shift to spatial matrix\")\n",
    "        A_sh = apply_shifts(cnmds['A'], shifts)\n",
    "        b_sh = apply_shifts(cnmds['b'], shifts)\n",
    "        cnmds_sh = xr.merge([A_sh, b_sh])\n",
    "        print(\"saving results\")\n",
    "        cnmds_sh.to_netcdf(anm_path + os.sep + \"cnm_anm_sh.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnmds = xr.open_mfdataset(get_cnm_list(dpath, pattern=r'^cnm_anm_sh.nc$'), concat_dim='animal')\n",
    "shiftds = xr.open_mfdataset(get_cnm_list(dpath, pattern=r'^cross_regi.nc$'), concat_dim='animal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cents = calculate_centroids(cnmds)\n",
    "cents.height = cents.height.astype(float)\n",
    "cents.width = cents.width.astype(float)\n",
    "cents.unit_id = cents.unit_id.astype(int)\n",
    "cents.animal = cents.animal.astype(str)\n",
    "cents.session = cents.session.astype(str)\n",
    "cents.session_id = cents.session_id.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dist = calculate_centroid_distance(cents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_ft = dist[dist['variable', 'distance'] < 5]\n",
    "dist_ft = group_by_session(dist_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings = calculate_mapping(dist_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_list = []\n",
    "for (cur_anm, cur_map), cur_grp in mappings.groupby([mappings['meta', 'animal'], mappings['meta', 'group']]):\n",
    "    novlp = len(cur_grp)\n",
    "    nunit = [len(cents[(cents['animal'] == cur_anm) & (cents['session'] == ss)]) for ss in cur_map]\n",
    "    nA = nunit[0]\n",
    "    nB = nunit[1]\n",
    "    nSum = np.sum(nunit) - novlp\n",
    "    cur_ovlp = pd.Series([cur_anm, cur_map, novlp/nSum, novlp/nA, novlp/nB], index=['animal', 'session', 'overlap', 'overlap-onA', 'overlap-onB'])\n",
    "    overlap_list.append(cur_ovlp)\n",
    "overlaps = pd.concat(overlap_list, axis=1, ignore_index=True).T\n",
    "group_dict = dict(MS101='negative', MS104='negative', NS20='negative', NS22='negative', MS102='neutral', MS103='neutral', NS24='neutral')\n",
    "overlaps['group'] = overlaps['animal'].apply(lambda anm: group_dict[anm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%opts BoxWhisker [width=1200, height=600, xrotation=90]\n",
    "overlap_ds = hv.Dataset(overlaps, kdims=['animal', 'session', 'group'], vdims=['overlap', 'overlap-onA', 'overlap-onB'])\n",
    "hv.HoloMap({val.name: hv.BoxWhisker(overlap_ds, kdims=['session', 'group'], vdims=[val]) for val in overlap_ds.vdims})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Curve [width=1000, height=400, xrotation=90, tools=['hover']]\n",
    "hv.HoloMap({\n",
    "    val.name: hv.NdLayout({\n",
    "        grp: hv.NdOverlay({\n",
    "            anm: hv.Curve(overlap_ds.select(group=grp, animal=anm), kdims=['session'], vdims=[val])\n",
    "            for anm, anm_df in grp_df.groupby('animal')})\n",
    "        for grp, grp_df in overlaps.groupby('group')}, kdims=['group']).cols(1)\n",
    "    for val in overlap_ds.vdims}).collate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Image [height=480, width=752]\n",
    "temps_ds = hv.Dataset(shiftds['temps'])\n",
    "temps_ds.to(hv.Image, ['width', 'height'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Image [height=480, width=752]\n",
    "temps_ds = hv.Dataset(shiftds['temps_shifted'])\n",
    "temps_ds.to(hv.Image, ['width', 'height'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "caiman",
   "language": "python",
   "name": "caiman"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
